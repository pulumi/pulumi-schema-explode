$token: aws:redshift/ClusterLogging:ClusterLogging
properties:
  bucketName:
    type: string
    description: |
      The name of an existing S3 bucket where the log files are to be stored. Must be in the same region as the cluster and the cluster must have read bucket and put object permissions.
      For more information on the permissions required for the bucket, please read the AWS [documentation](http://docs.aws.amazon.com/redshift/latest/mgmt/db-auditing.html#db-auditing-enable-logging)
    language:
      python:
        mapCase: false
  enable:
    type: boolean
    description: |
      Enables logging information such as queries and connection attempts, for the specified Amazon Redshift cluster.
    language:
      python:
        mapCase: false
  logDestinationType:
    type: string
    description: |
      The log destination type. An enum with possible values of `s3` and `cloudwatch`.
    language:
      python:
        mapCase: false
  logExports:
    type: array
    items:
      type: string
    description: |
      The collection of exported log types. Log types include the connection log, user log and user activity log. Required when `log_destination_type` is `cloudwatch`. Valid log types are `connectionlog`, `userlog`, and `useractivitylog`.
    language:
      python:
        mapCase: false
  s3KeyPrefix:
    type: string
    description: |
      The prefix applied to the log file names.
    language:
      python:
        mapCase: false
type: object
required:
  - enable
language:
  nodejs:
    requiredOutputs:
      - bucketName
      - enable
      - s3KeyPrefix
