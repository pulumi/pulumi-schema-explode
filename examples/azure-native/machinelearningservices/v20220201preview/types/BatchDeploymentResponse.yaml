$token: azure-native:machinelearningservices/v20220201preview:BatchDeploymentResponse
description: Batch inference settings per deployment.
properties:
  codeConfiguration:
    type: object
    $ref: "#/types/azure-native:machinelearningservices/v20220201preview:CodeConfigurationResponse"
    description: Code configuration for the endpoint deployment.
  compute:
    type: string
    description: Compute target for batch inference operation.
  description:
    type: string
    description: Description of the endpoint deployment.
  environmentId:
    type: string
    description: ARM resource ID of the environment specification for the endpoint deployment.
  environmentVariables:
    type: object
    additionalProperties:
      type: string
    description: Environment variables configuration for the deployment.
  errorThreshold:
    type: integer
    description: "Error threshold, if the error count for the entire input goes above this value,\r

      the batch inference will be aborted. Range is [-1, int.MaxValue].\r

      For FileDataset, this value is the count of file failures.\r

      For TabularDataset, this value is the count of record failures.\r

      If set to -1 (the lower bound), all failures during batch inference will be ignored."
    default: -1
  loggingLevel:
    type: string
    description: Logging level for batch inference operation.
    default: Info
  maxConcurrencyPerInstance:
    type: integer
    description: Indicates maximum number of parallelism per instance.
    default: 1
  miniBatchSize:
    type: number
    description: "Size of the mini-batch passed to each batch invocation.\r

      For FileDataset, this is the number of files per mini-batch.\r

      For TabularDataset, this is the size of the records in bytes, per mini-batch."
    default: 10
  model:
    oneOf:
      - type: object
        $ref: "#/types/azure-native:machinelearningservices/v20220201preview:DataPathAssetReferenceResponse"
      - type: object
        $ref: "#/types/azure-native:machinelearningservices/v20220201preview:IdAssetReferenceResponse"
      - type: object
        $ref: "#/types/azure-native:machinelearningservices/v20220201preview:OutputPathAssetReferenceResponse"
    discriminator:
      propertyName: referenceType
      mapping:
        DataPath: "#/types/azure-native:machinelearningservices/v20220201preview:DataPathAssetReferenceResponse"
        Id: "#/types/azure-native:machinelearningservices/v20220201preview:IdAssetReferenceResponse"
        OutputPath: "#/types/azure-native:machinelearningservices/v20220201preview:OutputPathAssetReferenceResponse"
    description: Reference to the model asset for the endpoint deployment.
  outputAction:
    type: string
    description: Indicates how the output will be organized.
    default: AppendRow
  outputFileName:
    type: string
    description: Customized output file name for append_row output action.
    default: predictions.csv
  properties:
    type: object
    additionalProperties:
      type: string
    description: Property dictionary. Properties can be added, but not removed or altered.
  provisioningState:
    type: string
    description: Provisioning state for the endpoint deployment.
  resources:
    type: object
    $ref: "#/types/azure-native:machinelearningservices/v20220201preview:ResourceConfigurationResponse"
    description: "Indicates compute configuration for the job.\r

      If not provided, will default to the defaults defined in ResourceConfiguration."
  retrySettings:
    type: object
    $ref: "#/types/azure-native:machinelearningservices/v20220201preview:BatchRetrySettingsResponse"
    description: "Retry Settings for the batch inference operation.\r

      If not provided, will default to the defaults defined in BatchRetrySettings."
type: object
required:
  - provisioningState
